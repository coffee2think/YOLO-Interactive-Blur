import cv2
import numpy as np
import sys
from pathlib import Path
from PIL import Image
from ultralytics import YOLO


# Chapter 3ì˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ëŠ” ë°ì´í„° êµ¬ì¡° ì •ì˜
# ì›¹ ì—°ë™ ì‹œ ì´ êµ¬ì¡°ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.

class DetectionModule:
    """
    ì´ë¯¸ì§€ ë¶„ì„ ì‹¤ìŠµì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ í†µí•©í•œ ê°ì²´ íƒì§€ ëª¨ë“ˆ.
    - YOLOv8n ëª¨ë¸ ì‚¬ìš© (model=yolov8n.pt)
    - CPU ëª¨ë“œ ê°•ì œ ì‹¤í–‰
    - ì¶œë ¥: ì‹œê°í™”ëœ PIL Image + Ch3 JSON ìŠ¤í‚¤ë§ˆ í˜•íƒœì˜ íƒì§€ ë°ì´í„°
    """

    # YOLO ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ëŠ” í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ê´€ë¦¬ (ì›¹ ì„œë²„ í™•ì¥ì„± ê³ ë ¤)
    MODEL = None

    def __init__(self, model_name: str = '../yolov8n.pt'):
        """
        DetectionModule ì´ˆê¸°í™”. ëª¨ë¸ì€ ìµœì´ˆ 1íšŒë§Œ ë¡œë“œí•©ë‹ˆë‹¤.

        Args:
            model_name (str): ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: 'yolov8n.pt' ë˜ëŠ” 'yolov8n-seg.pt').
        """
        if DetectionModule.MODEL is None:
            print(f"YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name} (CPU ê°•ì œ)...")
            try:
                # GPU ë¦¬ì†ŒìŠ¤ ì œí•œì„ ê³ ë ¤í•˜ì—¬ device='cpu'ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
                DetectionModule.MODEL = YOLO(model_name)
                print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (CPU ëª¨ë“œ).")
            except Exception as e:
                print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
                DetectionModule.MODEL = None

        self.model = DetectionModule.MODEL

        # Segmentation ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (ë¸”ëŸ¬ í™•ì¥ ë°©ì•ˆ ëŒ€ë¹„)
        self.is_seg_model = '-seg' in model_name

    def detect_objects(self, image_path: str | Path):
        """
        ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œì—ì„œ ê°ì²´ë¥¼ íƒì§€í•˜ê³  ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            image_path (str | Path): íƒì§€í•  ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œ. (ì˜ˆ: 'data/inputs/image.jpg')

        Returns:
            tuple: (visualized_image_pil, structured_data)
                   - visualized_image_pil (PIL.Image or None): íƒì§€ ê²°ê³¼ê°€ ì‹œê°í™”ëœ PIL ì´ë¯¸ì§€ ê°ì²´.
                   - structured_data (dict or None): Chapter 3 JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¥´ëŠ” Python ë”•ì…”ë„ˆë¦¬.
        """
        if self.model is None:
            print("ì˜¤ë¥˜: YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
            return None, None

        image_path = Path(image_path)
        if not image_path.is_file():
            print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}", file=sys.stderr)
            return None, None

        # 1. ê°ì²´ íƒì§€ ì‹¤í–‰ (CPU ê°•ì œ)
        # result ê°ì²´ëŠ” ê°ì§€ ì´ë¯¸ì§€, ë°”ìš´ë”© ë°•ìŠ¤, í´ë˜ìŠ¤ ID, ì‹ ë¢°ë„ ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.
        results = self.model(
            source=image_path,
            device='cpu',
            verbose=False,
            # YOLO CLI ì‹¤ìŠµ í”Œë¡œìš°ë¥¼ ë”°ë¼ TXT ë¼ë²¨ ì €ì¥ì„ í‰ë‚´ë‚´ê³  ë°ì´í„° íŒŒì‹± (save_txt=True)
            save_txt=False,  # ì‹¤ì œ íŒŒì¼ ì €ì¥ì€ ì´ ëª¨ë“ˆì—ì„œ ì§ì ‘ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            save_conf=True
        )

        if not results:
            print("íƒì§€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        result = results[0]  # ë‹¨ì¼ ì´ë¯¸ì§€ì´ë¯€ë¡œ ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ì‚¬ìš©

        # 2. ì´ë¯¸ì§€ ì •ë³´ ë¡œë“œ (Ch3 JSON ìŠ¤í‚¤ë§ˆì˜ width/height í™•ë³´)
        # result.orig_imgë¥¼ ì‚¬ìš©í•´ ì›ë³¸ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
        height, width = result.orig_img.shape[:2]

        # 3. íƒì§€ ê²°ê³¼ íŒŒì‹± ë° JSON ìŠ¤í‚¤ë§ˆ êµ¬ì¡°í™” (export_detections.py/refine_detections.pyì˜ ëª©ì  í†µí•©)
        detections_list = []

        # classes ì´ë¦„ ë§¤í•‘ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (refine_detections.py ì°¸ê³ )
        class_names_map = self.model.names

        # result.boxes.dataëŠ” [x1, y1, x2, y2, conf, cls] í˜•íƒœì˜ í…ì„œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
        for i, box in enumerate(result.boxes):
            # í”½ì…€ ì¢Œí‘œ (x1, y1, x2, y2)
            xyxy_pixels = [int(val) for val in box.xyxy[0].tolist()]
            x1, y1, x2, y2 = xyxy_pixels

            # ì •ê·œí™” ì¢Œí‘œ (cx, cy, w, h) - YOLO TXT í¬ë§·ê³¼ ìœ ì‚¬
            # box.xywhn[0].tolist()ëŠ” ì •ê·œí™”ëœ cx, cy, w, hë¥¼ ë°˜í™˜
            cx_norm, cy_norm, w_norm, h_norm = [round(val, 4) for val in box.xywhn[0].tolist()]

            confidence = round(box.conf[0].item(), 4)
            class_id = int(box.cls[0].item())
            class_name = class_names_map.get(class_id, 'unknown')

            # Segmentation ë°ì´í„° ì¶”ì¶œ (í™•ì¥ ë°©ì•ˆ)
            segmentation_mask_data = None
            if self.is_seg_model and result.masks and i < len(result.masks.data):
                # ë¸”ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë§ˆìŠ¤í¬ í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
                # (H, W) í˜•íƒœì˜ ì´ì§„ ë§ˆìŠ¤í¬ (0 ë˜ëŠ” 1)
                mask_tensor = result.masks.data[i]
                segmentation_mask_data = mask_tensor.cpu().numpy().tolist()  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì§ë ¬í™” ì¤€ë¹„

            detection_record = {
                # Chapter 3 JSON ìŠ¤í‚¤ë§ˆ í•„ë“œ
                "object_id": i,
                "class_id": class_id,
                "class_name": class_name,
                "confidence": confidence,
                "bbox": {"x1": x1, "y1": y1, "x2": x2, "y2": y2},  # í”½ì…€ ì¢Œí‘œ
                "bbox_norm": {"cx": cx_norm, "cy": cy_norm, "w": w_norm, "h": h_norm},  # ì •ê·œí™” ì¢Œí‘œ
                # ë¸”ëŸ¬ ì²˜ë¦¬ í™•ì¥ì„ ìœ„í•œ ì¶”ê°€ í•„ë“œ
                "segmentation_mask_data": segmentation_mask_data if segmentation_mask_data else None
            }
            detections_list.append(detection_record)

        # 4. ì‹œê°í™”ëœ ì´ë¯¸ì§€ ìƒì„±
        # result.plot()ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤, ë¼ë²¨ì´ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ (NumPy BGR)ë¥¼ ì–»ìŠµë‹ˆë‹¤.
        annotated_frame_bgr = result.plot()

        # íƒì§€ëœ ê°ì²´ì— ë²ˆí˜¸ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì¶”ê°€
        for det in detections_list:
            obj_id = det['object_id']
            x1, y1 = det['bbox']['x1'], det['bbox']['y1']
            label = f"#{obj_id}"
            
            # Bbox ë‚´ë¶€ ì¢Œìƒë‹¨ì— ë²ˆí˜¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            text_origin = (x1 + 5, y1 + 30)
            cv2.putText(annotated_frame_bgr, label, text_origin, 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2, cv2.LINE_AA)

        annotated_frame_rgb = cv2.cvtColor(annotated_frame_bgr, cv2.COLOR_BGR2RGB)
        visualized_image_pil = Image.fromarray(annotated_frame_rgb)

        # 5. ìµœì¢… êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„± (Ch3 JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¦„)
        structured_data = {
            "image": image_path.name,
            "width": width,
            "height": height,
            "detections": detections_list,
            # ë©”íƒ€ ì •ë³´ëŠ” refine_detections.pyì˜ í˜•ì‹ì„ ë”°ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ìƒëµ
            # "meta": {"num_detections": len(detections_list), ...}
        }

        return visualized_image_pil, structured_data


# ----------------------------------------------------------------------
# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ (Ch1/Ch3ì˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í”Œë¡œìš° ì°¸ê³ )
if __name__ == '__main__':
    # ì‹¤ìŠµ í´ë” êµ¬ì¡° ì¤€ìˆ˜: data/inputs
    ROOT_DIR = Path.cwd()
    INPUT_DIR = ROOT_DIR / "data" / "inputs"
    OUTPUT_DIR = ROOT_DIR / "data" / "outputs"

    # ë””ë ‰í„°ë¦¬ ìƒì„± (ì‹¤ìŠµ í”Œë¡œìš° ì°¸ê³ )
    INPUT_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # ğŸš¨ í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì‹¤ìŠµ READMEì˜ 'input.webp'ë¥¼ ê°€ì •)
    test_image_filename = 'input.jpg'
    test_image_path = INPUT_DIR / test_image_filename

    if not test_image_path.is_file():
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± ë˜ëŠ” ì‚¬ìš©ìì—ê²Œ ìš”ì²­
        print(f"'{test_image_path}' íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        # ì„ì‹œë¡œ ê²€ì€ìƒ‰ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)
        cv2.putText(dummy_img, "PLACEHOLDER", (100, 320), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)
        cv2.imwrite(str(test_image_path), dummy_img)
        print("ë”ë¯¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. íƒì§€ ê²°ê³¼ëŠ” ì˜ë¯¸ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 1. ëª¨ë“ˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (yolov8n.pt ì‚¬ìš©)
    # Segmentation ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ 'yolov8n-seg.pt'ë¡œ ë³€ê²½í•˜ì„¸ìš”.
    detector = DetectionModule(model_name='yolov8n.pt')

    # 2. ê°ì²´ íƒì§€ ìˆ˜í–‰
    print(f"\n'{test_image_path.name}' ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘...")
    visualized_img_pil, structured_detections = detector.detect_objects(test_image_path)

    # 3. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥

    # 3-1. ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ (Ch2/Ch3 í”Œë¡œìš° ì°¸ê³ )
    output_image_path = OUTPUT_DIR / f"annotated_{test_image_filename.split('.')[0]}.jpg"
    if visualized_img_pil:
        visualized_img_pil.save(output_image_path)
        print(f"\nâœ… ì‹œê°í™”ëœ ì´ë¯¸ì§€ê°€ '{output_image_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 3-2. ì •ì œëœ ê°ì§€ JSON ë°ì´í„° ì¶œë ¥ ë° ì €ì¥ (Ch3 í”Œë¡œìš° ì°¸ê³ )
    import json

    output_json_path = OUTPUT_DIR / "detections_refined.json"

    if structured_detections:
        # JSON í¬ë§·ìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(structured_detections, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… ì •ì œëœ íƒì§€ ë°ì´í„°ê°€ '{output_json_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ì½˜ì†” ì¶œë ¥ (detection_summary.pyì˜ ìš”ì•½ ê¸°ëŠ¥ ëŒ€ìš©)
        print("\n=== ì •ì œëœ íƒì§€ ê²°ê³¼ ìš”ì•½ (Structured Data) ===")
        print(
            f"ì´ë¯¸ì§€: {structured_detections.get('image')}, í¬ê¸°: {structured_detections.get('width')}x{structured_detections.get('height')}")
        for i, det in enumerate(structured_detections['detections']):
            seg_status = " (Segmentation O)" if det.get('segmentation_mask_data') else ""
            print(
                f"  - #{i}: [{det['class_id']}] {det['class_name']}: Conf={det['confidence']:.4f}, "
                f"Pixel Box={det['bbox']}"
                f"{seg_status}"
            )
    else:
        print("\nâŒ íƒì§€ëœ ê°ì²´ê°€ ì—†ê±°ë‚˜ ë°ì´í„° êµ¬ì¡°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
